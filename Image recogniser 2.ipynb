{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34857099-ff81-4fa3-a9cc-8617201c1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8e15536-b6eb-4567-89f9-79bf7e85bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining data location \n",
    "train_folder = r\"C:\\Users\\Lenovo\\Desktop\\vlg-dataset\\train\"\n",
    "test_folder = r\"C:\\Users\\Lenovo\\Desktop\\vlg-dataset\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "007ecd2b-9917-4a4b-92d3-18a1a1bf024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading  a pre-trained ResNet-18 model\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81993186-5cc9-4826-872b-7a1fe4702c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 40 \n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08bd4f06-eff0-43db-a899-ef148064802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the model on CUDA \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "954cce3c-2c3b-41f2-b141-52c886272bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1740fab0-30ac-4fd2-a1cd-565eb4e5aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "num_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1c2f5b2-95dd-4c90-8f1d-cfed62643b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the changes made to the images \n",
    "changes_to_image = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.RandomHorizontalFlip(), #randomly flip some images \n",
    "    transforms.RandomRotation(10),      # Randomly rotate images by 10 degrees\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a436ea9-4664-4757-8824-e636b526e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data into the system from the files \n",
    "\n",
    "train_dataset = ImageFolder(root=train_folder, transform=changes_to_image)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531ddf4-7fbb-4c44-b767-7f3d9433cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop of the model \n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d232680f-ad97-4433-b805-b75e99827b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the images with the trained model \n",
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "for img_name in os.listdir(test_folder):\n",
    "    img_path = os.path.join(test_folder, img_name)\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image = changes_to_image(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "        test_predictions.append((img_name, train_dataset.classes[predicted_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b615b25-3323-4c44-b4b0-ddbfe5c7224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the predictions \n",
    "submission = pd.DataFrame(test_predictions, columns=[\"image_id\", \"class\"])\n",
    "submission.to_csv(\"submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a20f5-f23e-484f-a73c-4bbb0b7833a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc6b4a-a282-4de2-9e50-43d06772b932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b2e4d-6c57-4724-b2bc-cd388b84c326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae316dc3-ac9b-41b1-bbc7-dcb04bbdaae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2181415-39d1-46a9-8914-d308bf2e69bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2475b0-6112-4344-8fe3-c76cb61ece4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
